Baseline LSTM-Reg results obtained from running the following command:
python -m models.reg_lstm --dataset DATASET_NAME_HERE --mode static --batch-size 32 --lr 0.01 --epochs 30 --bidirectional --num-layers 1 --hidden-dim 512 --wdrop 0.1 --embed-droprate 0.2 --dropout 0.5 --beta-ema 0.99 --seed 3435

---

AAPD:
Early Stopping. Epoch: 23, Best Dev F1: 0.7280804302080899
Evaluation metrics for dev
['accuracy', 'precision', 'recall', 'f1', 'cross_entropy_loss']
[0.401, 0.8295151838039425, 0.64875, 0.7280804302080899, 3.4393811359405517]
Evaluation metrics for test
['accuracy', 'precision', 'recall', 'f1', 'cross_entropy_loss']
[0.373, 0.8069148936170213, 0.6266005782734407, 0.7054173448035339, 3.6402577171325685]

---

IMDB (very large dataset): Receive cuda runtime error running this

---

Reuters:
Early Stopping. Epoch: 24, Best Dev F1: 0.8847583643122677
Evaluation metrics for dev
['accuracy', 'precision', 'recall', 'f1', 'cross_entropy_loss']
[0.822439526505404, 0.9262820512820513, 0.8467978233570531, 0.8847583643122677, 1.2478587969148267]
Evaluation metrics for test
['accuracy', 'precision', 'recall', 'f1', 'cross_entropy_loss']
[0.8088771116263663, 0.9233363998773383, 0.8042200854700855, 0.8596716630977873, 1.5379126856989755]

---

SST-2: This dataset is not listed in the paper but is provided in hedwig-data.
Early Stopping. Epoch: 13, Best Dev F1: 0.8451834862385322
Evaluation metrics for dev
['accuracy', 'precision', 'recall', 'f1', 'cross_entropy_loss']
[0.8451834862385321, 0.8451834862385321, 0.8451834862385321, 0.8451834862385322, 0.43584572243581127]
Evaluation metrics for test
['accuracy', 'precision', 'recall', 'f1', 'cross_entropy_loss']
[0.8308621636463481, 0.8308621636463481, 0.8308621636463481, 0.8308621636463481, 0.361538493718373]

---

Yelp2014:
There is no Yelp dataset provided in hedwig-data even though it is listed in the paper.